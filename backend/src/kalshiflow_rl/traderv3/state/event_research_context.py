"""
Event Research Context - Data structures for event-first research pipeline.

This module provides data structures for the event-first agentic research architecture,
which researches events holistically before evaluating individual markets.

Architecture:
    1. EVENT DISCOVERY: Group tracked markets by event_ticker
    2. EVENT RESEARCH: "What is this event about?"
    3. KEY DRIVER IDENTIFICATION: "What single factor determines YES vs NO?"
    4. EVIDENCE GATHERING: Targeted search for key driver data
    5. MARKET EVALUATION: Batch assess all markets with shared event context
    6. TRADE DECISIONS: Execute on mispriced markets

Design Principles:
    - Event context is shared across all markets in an event
    - Key driver analysis uses first-principles reasoning
    - Evidence is gathered specifically for the identified key driver
    - Market evaluation includes microstructure signals
"""

import time
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List
from enum import Enum


class EvidenceReliability(Enum):
    """Reliability classification for gathered evidence."""
    HIGH = "high"        # Official sources, recent data, multiple confirmations
    MEDIUM = "medium"    # Credible sources but older or single source
    LOW = "low"          # Unverified, speculative, or conflicting


class Confidence(Enum):
    """Confidence level in assessment."""
    HIGH = "high"        # Strong evidence, clear causal chain
    MEDIUM = "medium"    # Reasonable evidence, some uncertainty
    LOW = "low"          # Weak evidence, high uncertainty


@dataclass
class EventContext:
    """
    Phase 2 output: Understanding of what the event is about.

    Generated by LLM analysis of event metadata and initial research.
    """
    # What is this event about?
    event_description: str              # 2-3 sentence description
    core_question: str                  # The fundamental question being asked

    # How will outcome be determined?
    resolution_criteria: str            # What determines YES vs NO
    resolution_objectivity: str         # "objective", "subjective", "mixed"

    # Time horizon
    time_horizon: str                   # When will we know the outcome
    key_dates: List[str] = field(default_factory=list)  # Important dates before resolution


@dataclass
class KeyDriverAnalysis:
    """
    Phase 3 output: Identification of what determines the outcome.

    Generated by LLM causal reasoning about the event.
    """
    # Primary driver
    primary_driver: str                 # The single most important factor
    primary_driver_reasoning: str       # Why this factor matters most
    causal_chain: str                   # How driver â†’ outcome

    # Secondary factors
    secondary_factors: List[str] = field(default_factory=list)
    secondary_importance: str = ""      # How much they matter relative to primary

    # Tail risks
    tail_risks: List[str] = field(default_factory=list)
    what_could_go_wrong: str = ""       # What would invalidate the analysis

    # Base rate
    base_rate: float = 0.5              # Historical frequency of YES (0-1)
    base_rate_reasoning: str = ""       # How base rate was determined
    comparable_events: str = ""         # What "similar events" means


@dataclass
class Evidence:
    """
    Phase 4 output: Evidence gathered for the key driver.

    Generated by web search targeted at the identified primary driver.
    """
    # Key evidence about the primary driver
    key_evidence: List[str] = field(default_factory=list)
    evidence_summary: str = ""          # One paragraph summary

    # Sources
    sources: List[str] = field(default_factory=list)
    sources_checked: int = 0

    # Reliability assessment
    reliability: EvidenceReliability = EvidenceReliability.MEDIUM
    reliability_reasoning: str = ""

    # What evidence suggests
    evidence_probability: float = 0.5   # What probability evidence implies


@dataclass
class EventResearchContext:
    """
    Complete event-level research context shared across all markets in an event.

    This is the primary output of Phases 1-4, used as input to Phase 5 (market evaluation).
    """
    # Event identification
    event_ticker: str
    event_title: str
    event_category: str

    # Phase 2: Event understanding
    context: EventContext = field(default_factory=lambda: EventContext(
        event_description="",
        core_question="",
        resolution_criteria="",
        resolution_objectivity="unknown",
        time_horizon="",
    ))

    # Phase 3: Key driver analysis
    driver_analysis: KeyDriverAnalysis = field(default_factory=KeyDriverAnalysis)

    # Phase 4: Evidence
    evidence: Evidence = field(default_factory=Evidence)

    # Markets in this event
    market_tickers: List[str] = field(default_factory=list)

    # Metadata
    researched_at: float = field(default_factory=time.time)
    research_duration_seconds: float = 0.0
    llm_calls_made: int = 0

    def to_prompt_string(self) -> str:
        """Format event research context for LLM prompt consumption."""
        lines = []

        # Event description
        lines.append(f"EVENT: {self.event_title}")
        lines.append(f"CATEGORY: {self.event_category}")
        lines.append("")
        lines.append(f"DESCRIPTION: {self.context.event_description}")
        lines.append(f"CORE QUESTION: {self.context.core_question}")
        lines.append(f"RESOLUTION: {self.context.resolution_criteria}")
        lines.append(f"TIME HORIZON: {self.context.time_horizon}")

        # Key driver
        lines.append("")
        lines.append(f"PRIMARY DRIVER: {self.driver_analysis.primary_driver}")
        lines.append(f"WHY: {self.driver_analysis.primary_driver_reasoning}")
        lines.append(f"CAUSAL CHAIN: {self.driver_analysis.causal_chain}")

        # Base rate
        lines.append("")
        lines.append(f"BASE RATE: {self.driver_analysis.base_rate:.0%} for similar events")
        lines.append(f"REASONING: {self.driver_analysis.base_rate_reasoning}")

        # Secondary factors
        if self.driver_analysis.secondary_factors:
            lines.append("")
            lines.append("SECONDARY FACTORS:")
            for factor in self.driver_analysis.secondary_factors:
                lines.append(f"  - {factor}")

        # Tail risks
        if self.driver_analysis.tail_risks:
            lines.append("")
            lines.append("TAIL RISKS:")
            for risk in self.driver_analysis.tail_risks:
                lines.append(f"  - {risk}")

        # Evidence
        lines.append("")
        lines.append(f"EVIDENCE ({self.evidence.reliability.value} reliability):")
        lines.append(self.evidence.evidence_summary)
        if self.evidence.key_evidence:
            for ev in self.evidence.key_evidence[:5]:  # Top 5 evidence points
                lines.append(f"  - {ev}")

        return "\n".join(lines)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for logging/storage."""
        return {
            "event_ticker": self.event_ticker,
            "event_title": self.event_title,
            "event_category": self.event_category,
            "context": {
                "event_description": self.context.event_description,
                "core_question": self.context.core_question,
                "resolution_criteria": self.context.resolution_criteria,
                "resolution_objectivity": self.context.resolution_objectivity,
                "time_horizon": self.context.time_horizon,
                "key_dates": self.context.key_dates,
            },
            "driver_analysis": {
                "primary_driver": self.driver_analysis.primary_driver,
                "primary_driver_reasoning": self.driver_analysis.primary_driver_reasoning,
                "causal_chain": self.driver_analysis.causal_chain,
                "secondary_factors": self.driver_analysis.secondary_factors,
                "tail_risks": self.driver_analysis.tail_risks,
                "base_rate": self.driver_analysis.base_rate,
                "base_rate_reasoning": self.driver_analysis.base_rate_reasoning,
            },
            "evidence": {
                "key_evidence": self.evidence.key_evidence,
                "evidence_summary": self.evidence.evidence_summary,
                "sources": self.evidence.sources,
                "reliability": self.evidence.reliability.value,
                "evidence_probability": self.evidence.evidence_probability,
            },
            "market_tickers": self.market_tickers,
            "researched_at": self.researched_at,
            "research_duration_seconds": self.research_duration_seconds,
            "llm_calls_made": self.llm_calls_made,
        }


@dataclass
class MarketAssessment:
    """
    Phase 5 output: Per-market assessment within an event.

    Generated by applying event context + key driver to specific market question.
    """
    market_ticker: str
    market_title: str

    # The specific question this market asks
    specific_question: str = ""

    # How key driver applies to this market
    driver_application: str = ""        # How does primary driver affect THIS market?

    # Probability assessment
    evidence_probability: float = 0.5   # What evidence suggests
    market_probability: float = 0.5     # Current market price / 100
    mispricing_magnitude: float = 0.0   # evidence - market (positive = underpriced YES)

    # Price calibration (blind estimation)
    price_guess_cents: Optional[int] = None       # LLM's blind guess of market price
    price_guess_error_cents: Optional[int] = None # guess - actual (positive = overestimated)

    # Recommendation
    recommendation: str = "HOLD"        # BUY_YES, BUY_NO, HOLD
    confidence: Confidence = Confidence.MEDIUM
    edge_explanation: str = ""          # Why market is mispriced

    # Microstructure (if available)
    microstructure_summary: str = ""    # Summary of trade flow / orderbook signals

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for logging/storage."""
        return {
            "market_ticker": self.market_ticker,
            "market_title": self.market_title,
            "specific_question": self.specific_question,
            "driver_application": self.driver_application,
            "evidence_probability": self.evidence_probability,
            "market_probability": self.market_probability,
            "mispricing_magnitude": self.mispricing_magnitude,
            "price_guess_cents": self.price_guess_cents,
            "price_guess_error_cents": self.price_guess_error_cents,
            "recommendation": self.recommendation,
            "confidence": self.confidence.value,
            "edge_explanation": self.edge_explanation,
            "microstructure_summary": self.microstructure_summary,
        }


@dataclass
class EventResearchResult:
    """
    Complete result of event-first research pipeline.

    Contains event context and all market assessments.
    """
    # Event-level context (shared)
    event_context: EventResearchContext

    # Per-market assessments
    assessments: List[MarketAssessment] = field(default_factory=list)

    # Summary statistics
    markets_evaluated: int = 0
    markets_with_edge: int = 0          # Markets with |mispricing| > threshold
    total_research_seconds: float = 0.0

    # Status
    success: bool = True
    error_message: Optional[str] = None

    def get_tradeable_assessments(
        self,
        min_mispricing: float = 0.10,
        min_confidence: Confidence = Confidence.MEDIUM,
    ) -> List[MarketAssessment]:
        """Get assessments that meet trading thresholds."""
        tradeable = []
        for assessment in self.assessments:
            if assessment.recommendation == "HOLD":
                continue
            if abs(assessment.mispricing_magnitude) < min_mispricing:
                continue
            # Confidence ordering: HIGH > MEDIUM > LOW
            confidence_order = {Confidence.HIGH: 3, Confidence.MEDIUM: 2, Confidence.LOW: 1}
            if confidence_order.get(assessment.confidence, 0) < confidence_order.get(min_confidence, 0):
                continue
            tradeable.append(assessment)
        return tradeable

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for logging/storage."""
        return {
            "event_context": self.event_context.to_dict(),
            "assessments": [a.to_dict() for a in self.assessments],
            "markets_evaluated": self.markets_evaluated,
            "markets_with_edge": self.markets_with_edge,
            "total_research_seconds": self.total_research_seconds,
            "success": self.success,
            "error_message": self.error_message,
        }
